{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd42457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥  reading CSV …\n",
      "✅ saved ..\\data\\processed\\my_nq\\raw_lob.npy   4,236,994 rows × 41 cols\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "import_raw_lob_ms.py\n",
    "────────────────────\n",
    "Loads a DOM CSV whose first column is *Unix-epoch milliseconds*\n",
    "and saves it as a NumPy array:\n",
    "    • ts  → float64  seconds (millisecond resolution preserved)\n",
    "    • all price/size columns → float32\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────── configuration ─────────\n",
    "CSV_PATH = Path(\"../data/raw-sierra/dom-datatick.csv\")\n",
    "OUT_DIR  = Path(\"../data/processed/my_nq\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_LEVELS = 10\n",
    "COLS = ([\"ts_ms\"] +\n",
    "        [f\"bid_px{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"bid_sz{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"ask_px{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"ask_sz{i}\" for i in range(N_LEVELS)])\n",
    "\n",
    "print(\"📥  reading CSV …\")\n",
    "df = pd.read_csv(CSV_PATH, names=COLS)\n",
    "\n",
    "# ── keep timestamp in float64 seconds, others in float32 ──\n",
    "ts_sec   = (df[\"ts_ms\"].astype(np.float64) / 1_000.0).to_numpy()      # 64-bit\n",
    "features = df.iloc[:, 1:].astype(np.float32).to_numpy()               # 40 × float32\n",
    "\n",
    "raw = np.column_stack([ts_sec, features])      # shape (rows, 41)\n",
    "\n",
    "out_path = OUT_DIR / \"raw_lob.npy\"\n",
    "np.save(out_path, raw)\n",
    "print(f\"✅ saved {out_path}   {raw.shape[0]:,} rows × {raw.shape[1]} cols\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c3bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 dedup + 100 ms → 9,551,796 rows\n",
      "✅ saved raw_lob_100ms.npy  (9551796, 41)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed/my_nq\")\n",
    "raw      = np.load(DATA_DIR / \"raw_lob.npy\", mmap_mode=\"r\")\n",
    "\n",
    "N_LEVELS = 10\n",
    "COLS = ([\"ts\"] +\n",
    "        [f\"bid_px{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"bid_sz{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"ask_px{i}\" for i in range(N_LEVELS)] +\n",
    "        [f\"ask_sz{i}\" for i in range(N_LEVELS)])\n",
    "\n",
    "df = pd.DataFrame(raw, columns=COLS, copy=False)\n",
    "\n",
    "# df['ts'] is now float64 seconds with millisecond fractions\n",
    "df[\"ts_dt\"] = pd.to_datetime(df[\"ts\"], unit=\"s\")\n",
    "\n",
    "# 1. drop consecutive duplicates\n",
    "mask_change = (df.iloc[:, 1:] != df.iloc[:, 1:].shift()).any(axis=1)\n",
    "df = df.loc[mask_change]\n",
    "\n",
    "# 2. resample to fixed 100 ms grid\n",
    "df = (df.set_index(\"ts_dt\")\n",
    "        .resample(\"100ms\", label=\"right\", closed=\"right\")\n",
    "        .last()\n",
    "        .ffill())\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"📉 dedup + 100 ms → {len(df):,} rows\")\n",
    "\n",
    "raw_100ms = df[COLS].to_numpy(dtype=np.float32, copy=False)\n",
    "np.save(DATA_DIR / \"raw_lob_100ms.npy\", raw_100ms)\n",
    "print(f\"✅ saved raw_lob_100ms.npy  {raw_100ms.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d34593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥  Loading raw_lob_100ms.npy …\n",
      "   → 9,551,796 snapshots\n",
      "⚙️  Compiling & running fast labeller …\n",
      "✅ Saved ..\\data\\processed\\my_nq\\labels_30s.npy\n",
      "   positives: 135,410  (1.42%)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "make_labels_30s_fast.py\n",
    "───────────────────────\n",
    "Create binary labels for NQ DOM snapshots:\n",
    "\n",
    " label = 1  ⇐  within the next 30 s\n",
    "                 • mid-price falls ≥ 4 ticks  (4 × 0.25 = 1.00 pt)\n",
    "                 • AND never rises > 2 ticks (2 × 0.25 = 0.50 pt)\n",
    " label = 0  otherwise\n",
    "\n",
    "Runs ~20–50× faster than a naive loop by using two monotone de-ques and Numba.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from numba import njit\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 1. CONFIGURATION\n",
    "# ───────────────────────────────────────────────────────────\n",
    "DATA_DIR   = Path(\"../data/processed/my_nq\")         # adjust if needed\n",
    "RAW_FILE   = DATA_DIR / \"raw_lob_100ms.npy\"          # floats with ms ts\n",
    "LABEL_FILE = DATA_DIR / \"labels_30s.npy\"\n",
    "\n",
    "N_LEVELS   = 10           # depth recorded in each side of book\n",
    "TICK_SIZE  = 0.25         # CME NQ\n",
    "DROP_TICKS = 4            # ≥ 4 ticks down → 1.00 pt\n",
    "RISE_TICKS = 2            # ≤ 2 ticks up   → 0.50 pt\n",
    "HORIZON_S  = 30.0         # 30-second horizon\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 2. FAST LABELLER (Numba)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "@njit(cache=True)\n",
    "def label_drop_rule(ts, mid,\n",
    "                    tick_size, drop_ticks, rise_ticks, horizon):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts   : 1-D float64, seconds (ascending)\n",
    "    mid  : 1-D float32/64, mid prices\n",
    "    Returns\n",
    "    -------\n",
    "    labels : uint8 (0/1), same length as ts\n",
    "    \"\"\"\n",
    "    N = ts.shape[0]\n",
    "    labels = np.zeros(N, np.uint8)\n",
    "\n",
    "    dq_min = np.empty(N, np.int64)   # stores indices of future mins\n",
    "    dq_max = np.empty(N, np.int64)   # stores indices of future maxs\n",
    "    head_min = head_max = 0\n",
    "    tail_min = tail_max = 0\n",
    "\n",
    "    for i in range(N - 1, -1, -1):       # walk right → left\n",
    "        # drop indices outside horizon\n",
    "        while head_min < tail_min and ts[dq_min[head_min]] - ts[i] > horizon:\n",
    "            head_min += 1\n",
    "        while head_max < tail_max and ts[dq_max[head_max]] - ts[i] > horizon:\n",
    "            head_max += 1\n",
    "\n",
    "        # window min / max (if deque empty, mid[i] is both)\n",
    "        win_min = mid[dq_min[head_min]] if head_min < tail_min else mid[i]\n",
    "        win_max = mid[dq_max[head_max]] if head_max < tail_max else mid[i]\n",
    "\n",
    "        # apply rule\n",
    "        if (mid[i] - win_min >= drop_ticks * tick_size) and \\\n",
    "           (win_max - mid[i] <= rise_ticks * tick_size):\n",
    "            labels[i] = 1\n",
    "\n",
    "        # push current index into min-deque (monotone ↑)\n",
    "        while tail_min > head_min and mid[dq_min[tail_min - 1]] >= mid[i]:\n",
    "            tail_min -= 1\n",
    "        dq_min[tail_min] = i\n",
    "        tail_min += 1\n",
    "\n",
    "        # push into max-deque (monotone ↓)\n",
    "        while tail_max > head_max and mid[dq_max[tail_max - 1]] <= mid[i]:\n",
    "            tail_max -= 1\n",
    "        dq_max[tail_max] = i\n",
    "        tail_max += 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 3. LOAD RAW SNAPSHOTS\n",
    "# ───────────────────────────────────────────────────────────\n",
    "print(\"📥  Loading raw_lob_100ms.npy …\")\n",
    "raw = np.load(RAW_FILE, mmap_mode=\"r\")                  # (N, 41)\n",
    "\n",
    "bid0_col = 1\n",
    "ask0_col = 1 + 2 * N_LEVELS\n",
    "\n",
    "ts  = raw[:, 0].astype(np.float64)                      # float-seconds (ms kept)\n",
    "mid = (raw[:, bid0_col] + raw[:, ask0_col]) / 2.0       # mid-price series\n",
    "\n",
    "print(f\"   → {len(ts):,} snapshots\")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 4. GENERATE LABELS (JIT + RUN)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "print(\"⚙️  Compiling & running fast labeller …\")\n",
    "# tiny warm-up to trigger JIT\n",
    "_ = label_drop_rule(ts[:10], mid[:10],\n",
    "                    TICK_SIZE, DROP_TICKS, RISE_TICKS, HORIZON_S)\n",
    "\n",
    "# full dataset\n",
    "labels = label_drop_rule(ts, mid,\n",
    "                         TICK_SIZE, DROP_TICKS, RISE_TICKS, HORIZON_S)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 5. SAVE\n",
    "# ───────────────────────────────────────────────────────────\n",
    "np.save(LABEL_FILE, labels)\n",
    "pos = int(labels.sum())\n",
    "print(f\"✅ Saved {LABEL_FILE}\\n\"\n",
    "      f\"   positives: {pos:,}  ({pos/len(labels):.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a442bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "make_bucketed.py\n",
    "────────────────\n",
    "TLOB-style tokenisation for the resampled NQ DOM:\n",
    "\n",
    "    • price tokens  : relative tick distance from best bid / ask\n",
    "    • size  tokens  : log-compressed volumes, quantile-bucketed\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "bucketed_lob.npy  (int16)   ts | 2×N_LEVELS price_tok | 2×N_LEVELS size_tok\n",
    "size_edges.npy    (float32) 129 boundaries used for the volume buckets\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 1. paths & hyper-params\n",
    "# ───────────────────────────────────────────────────────────\n",
    "DATA_DIR     = Path(\"../data/processed/my_nq\")\n",
    "RAW_FILE     = DATA_DIR / \"raw_lob_100ms.npy\"\n",
    "BUCKET_FILE  = DATA_DIR / \"bucketed_lob.npy\"\n",
    "EDGES_FILE   = DATA_DIR / \"size_edges.npy\"\n",
    "\n",
    "N_LEVELS   = 10           # depth recorded\n",
    "TICK_SIZE  = 0.25         # CME NQ\n",
    "MAX_TICKS  = 50           # clip ±50 → 0-100 token range\n",
    "SZ_BUCKETS = 128          # number of volume buckets 0-127\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 2. load float snapshots\n",
    "# ───────────────────────────────────────────────────────────\n",
    "raw = np.load(RAW_FILE, mmap_mode=\"r\")        # (N, 41)\n",
    "\n",
    "ts_col      = raw[:, :1]                      # keep as int64/float64\n",
    "bid_px_idx  = np.arange(1, 1 + N_LEVELS)\n",
    "bid_sz_idx  = np.arange(1 + N_LEVELS, 1 + 2*N_LEVELS)\n",
    "ask_px_idx  = np.arange(1 + 2*N_LEVELS, 1 + 3*N_LEVELS)\n",
    "ask_sz_idx  = np.arange(1 + 3*N_LEVELS, 1 + 4*N_LEVELS)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 3. PRICE TOKENISATION  (relative ticks)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "best_bid = raw[:, bid_px_idx[0]][:, None]          # (N,1)\n",
    "best_ask = raw[:, ask_px_idx[0]][:, None]\n",
    "\n",
    "rel_bid = np.round((best_bid - raw[:, bid_px_idx]) / TICK_SIZE)\n",
    "rel_ask = np.round((raw[:, ask_px_idx] - best_ask) / TICK_SIZE)\n",
    "rel_ticks = np.hstack([rel_bid, rel_ask]).astype(np.int16)\n",
    "\n",
    "# clip & shift to 0 … 100\n",
    "rel_ticks = np.clip(rel_ticks, -MAX_TICKS, MAX_TICKS)\n",
    "price_tok = (rel_ticks + MAX_TICKS).astype(np.int16)        # (N, 20)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 4. SIZE TOKENISATION  (log1p + quantile buckets)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "log_sz   = np.log1p(raw[:, np.hstack([bid_sz_idx, ask_sz_idx])])\n",
    "# build equiprobable edges\n",
    "edges    = np.quantile(log_sz.ravel(), np.linspace(0, 1, SZ_BUCKETS + 1))\n",
    "edges[0]  = -np.inf                                    # left-open\n",
    "edges[-1] =  np.inf                                    # right-open\n",
    "\n",
    "size_tok = (np.searchsorted(edges, log_sz, \"right\") - 1).astype(np.int16)  # 0-127\n",
    "\n",
    "# sanity ranges\n",
    "assert price_tok.min() >= 0 and price_tok.max() <= 2*MAX_TICKS\n",
    "assert size_tok.min()  >= 0 and size_tok.max()  < SZ_BUCKETS\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "# 5. assemble & save\n",
    "# ───────────────────────────────────────────────────────────\n",
    "bucketed = np.concatenate(\n",
    "    [ts_col.astype(np.int64),       # keep timestamp\n",
    "     price_tok,\n",
    "     size_tok],\n",
    "    axis=1).astype(np.int16, copy=False)      # ts stays int64 underneath mmap\n",
    "\n",
    "np.save(BUCKET_FILE, bucketed)\n",
    "np.save(EDGES_FILE, edges.astype(np.float32))\n",
    "\n",
    "print(f\"✅ bucketed_lob.npy : {bucketed.shape}  (tokens)\")\n",
    "print(f\"✅ size_edges.npy   : {len(edges)} edges (0-{SZ_BUCKETS-1} tokens)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
